{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Reddit's API for Predicting Comments - Part 2\n",
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data saved in csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "list_of_posts_board = pd.DataFrame.from_csv(\"./list_of_posts_boardgame.csv\")\n",
    "\n",
    "list_of_posts_truered = pd.DataFrame.from_csv(\"./list_of_posts_true_reddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_of_posts_board), len(list_of_posts_truered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_posts_board_extract = []\n",
    "for post in list_of_posts_board['data'][1:]:\n",
    "    post = ast.literal_eval(post)\n",
    "    if post['selftext'] == '':\n",
    "        continue\n",
    "    else:\n",
    "        list_of_posts_board_extract.append(post['selftext'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_of_posts_board_extract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class 0 for \"True Reddits\" and 1 for \"Board Games\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_board = pd.DataFrame(list_of_posts_board_extract, columns=['post'])\n",
    "pd_board['class'] = 1\n",
    "pd_board.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_posts_truered_extract = []\n",
    "for post in list_of_posts_truered['data'][1:]:\n",
    "    post = ast.literal_eval(post)\n",
    "#    post_ext = {}\n",
    "    if post['title'] == '':\n",
    "        continue\n",
    "    else:\n",
    "#        post_ext['selftext'] = post['selftext']\n",
    "        \n",
    "        list_of_posts_truered_extract.append(post['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_of_posts_truered_extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_truered = pd.DataFrame(list_of_posts_truered_extract, columns=['post'])\n",
    "pd_truered['class'] = 0\n",
    "pd_truered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine two lists together\n",
    "list_concat = pd.concat([pd_board, pd_truered])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_concat.drop('class', axis = 1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_concat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_concat.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP\n",
    "#### Use CountVectorizer and TfidfVectorizer from scikit-learn to create features from the thread contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "cvec = CountVectorizer()\n",
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec_trans = cvec.fit_transform(list_concat['post'])\n",
    "tfidf_trans = tfidf.fit_transform(list_concat['post'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cvec = pd.DataFrame(cvec_trans.todense(), columns = cvec.get_feature_names())\n",
    "X_tfidf = pd.DataFrame(tfidf_trans.todense(), columns = tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cvec.iloc[:,2000:4000].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf.iloc[:,2000:4000].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting subreddit using Random Forest Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cvec.shape, X_tfidf.shape, list_concat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_cvec,list_concat['class'], test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X_tfidf,list_concat['class'], test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline accuracy for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_concat['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For this particular dataset, our baseline accuracy should be proportional to our data blance: 969/(969+811) = 54.4%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  RandomForestClassifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_train_predict = rf.predict(X_train)\n",
    "print(\"train accuracy score: \", rf.score(X_train, y_train).round(4))\n",
    "print(\"test accuracy score: \", rf.score(X_test, y_test).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf1 = RandomForestClassifier(random_state=42)\n",
    "rf1.fit(X1_train, y1_train)\n",
    "y1_train_predict = rf1.predict(X1_train)\n",
    "print(\"train accuracy score: \", rf1.score(X1_train, y1_train).round(4))\n",
    "print(\"test accuracy score: \", rf1.score(X1_test, y1_test).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Cross-validate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_scores_rf = cross_val_score(RandomForestClassifier(random_state=42), X_train, y_train)\n",
    "print(cross_scores_rf.mean().round(4))\n",
    "\n",
    "y_test_predict = rf.predict(X_test)\n",
    "report_test = classification_report(y_test, y_test_predict)\n",
    "print(report_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_scores_rf1 = cross_val_score(RandomForestClassifier(random_state=42), X1_train, y1_train)\n",
    "print(cross_scores_rf1.mean().round(4))\n",
    "\n",
    "y1_test_predict = rf1.predict(X1_test)\n",
    "report_test1 = classification_report(y1_test, y1_test_predict)\n",
    "print(report_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "* CountVectorizer and Tfidf create similar results and Tfidf vectorizer is sightly better in recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use GridSearchCV with Pipeline to optimize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(list_concat['post'], list_concat['class'], test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.fit(X_train_rf, y_train_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_score_.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.score(X_test_rf, y_test_rf).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predict = gs.predict(X_test_rf)\n",
    "report_test = classification_report(y_test_rf, y_test_predict)\n",
    "print(report_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model with Hyperparmeter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_function = make_scorer(accuracy_score)\n",
    "params_lr = {\n",
    "    \"cvec__stop_words\"  : [None, 'english'],\n",
    "    \"cvec__max_df\"      : [1.0, 3.0],\n",
    "    \"cvec__ngram_range\" : [(1,1), (1,2)],\n",
    "    \"cvec__lowercase\"   : ['True', 'False'],\n",
    "    \"logic__C\"  : [0.1 ,1 , 5],\n",
    "    \"logic__max_iter\"     : [5, 10, 20],\n",
    "    \"logic__random_state\"  : [42]\n",
    "             }\n",
    "steps_lr = [('cvec', CountVectorizer()), ('logic', LogisticRegression())]\n",
    "pipe_lr = Pipeline(steps = steps_lr)\n",
    "gs_lr = GridSearchCV(pipe_lr, param_grid = params_lr , scoring = score_function, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lr, X_test_lr, y_train_lr, y_test_lr = train_test_split(list_concat['post'], list_concat['class'], test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_lr.fit(X_train_lr, y_train_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_lr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_lr.best_score_.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_lr.score(X_test_lr, y_test_lr).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predict = gs.predict(X_test_lr)\n",
    "report_test = classification_report(y_test_lr, y_test_predict)\n",
    "print(report_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executive Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classify your Subreddit Post by Machine Learning!\n",
    "\n",
    "There are hundreds and thousands of posts per day on reddit.com and we definitely want computers to be able to “recognize” each post by its subreddit category for multiple usages!\n",
    "But how?\n",
    "\n",
    "Machine learning algorithms can easily help! In this project, we showcase how this is done by machine learning. Two popular kinds of subreddit posts are scrapped from reddit.com: Boardgames and True reddits. NLP is used next to analyze the word frequency for each post and a model is built on top of that to predict which category the post belongs to. The parameters are fine tuned later to optimize results. 96 of 100 posts can be categorized correctly.\n",
    "\n",
    "This project used logistic regression and random forest classifier for classification model and both gave very high accuracy scores of 95% ~ 96%. Logistic regression is sightly better and the difference is minor that they are essentially equivalent in terms of accuracy. The optimization using gridserachCV is very useful and compationaly expensive so a minimum optimization was carried out and good convergence on train and test scores achieved. The precision, recall and f1-score listed as a reference but accuracy is our target metrics cause we don't care to optimize either false negatives or false positives in this particular case.\n",
    "\n",
    "I believe there are more we can work to expand the results to a more diverse and in depth application. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
